name: Weekly Job Scraper

on:
  push:
    branches:
      - main
  schedule:
    - cron: '0 8 * * 1' # Runs at 08:00 UTC every Monday
  workflow_dispatch:      # Allows you to click "Run Now" button manually

permissions:
  contents: write

jobs:
  scrape_and_update:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          cache: 'pip' # caching pip dependencies

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          python -m pip install -r requirements.txt
          playwright install chromium
          python -m pip list

      - name: Debug Environment
        run: |
          echo "Checking scraper.py content (first 15 lines):"
          head -n 15 scraper.py
          echo "Checking tqdm installation:"
          python -c "import tqdm; print(tqdm.__version__)" || echo "tqdm import failed"

      - name: Run Scraper
        run: |
          python scraper.py

      - name: Generate Static Report
        run: |
          python generate_report.py

      - name: Commit and Push Data
        run: |
          git config --global user.name 'Scraper Bot'
          git config --global user.email 'bot@noreply.github.com'
          git add data/*.csv
          # Only commit if there are changes
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            git commit -m "Auto-update: Job market data [$(date +'%Y-%m-%d')]"
            git push
          fi

      - name: Deploy to GitHub Pages
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./public
